{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Literal\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO: finish implementation\n",
    "\n",
    "# class AcceleratedKMeans:\n",
    "#     \"\"\"\n",
    "#     Perform AcceleratedKMeans clustering on a dataset.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  algorithm : Literal['lloyd', 'extended-hartigan', 'safe-hartigan', 'hartigan', 'binary-hartigan'] = 'lloyd',\n",
    "#                  init : Literal['random', 'random-data', 'k-means++', 'maximin', 'greedy-k-means++'] = 'random',\n",
    "#                  seed : Union[int, None] = None):\n",
    "#         \"\"\"\n",
    "#         Initialize the KMeans object.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         algorithm : {'elkan', 'acc-hartigan'}\n",
    "#             Algorithm to use. Either 'elkan' or 'acc-hartigan'\n",
    "\n",
    "#         init : {'random', 'random-data', 'k-means++', 'maximin', 'greedy-k-means++'}\n",
    "#             Initialization method. Either 'random' or 'random-data' or 'k-means++' or 'maximin' or 'greedy-k-means++'\n",
    "\n",
    "#         seed : int\n",
    "#             Seed for random generator\n",
    "#         \"\"\"\n",
    "\n",
    "#         assert algorithm in ['elkan', 'acc-hartigan'], \"algorithm must be either 'elkan' or 'acc-hartigan'\"\n",
    "#         assert init in ['random', 'random-data', 'k-means++', 'maximin', 'greedy-k-means++'], \"init must be either 'random', 'random-data', 'k-means++', 'maximin', or 'greedy-k-means++'\"\n",
    "#         assert seed is None or isinstance(seed, int), \"seed must be an int or None\"\n",
    "\n",
    "#         self.algorithm = algorithm\n",
    "#         self.init = init\n",
    "#         self.seed = seed\n",
    "\n",
    "#         self.data = None\n",
    "#         self.k = None\n",
    "#         self.n_samples = None\n",
    "#         self.centroids = None\n",
    "#         self.y_pred = None\n",
    "#         self.tol = 1e-4\n",
    "\n",
    "#         self.l = None\n",
    "#         self.u = None\n",
    "\n",
    "#         self.safe_iterations = 0\n",
    "#         self.iterations = 0\n",
    "#         self.norm_calculations = 0\n",
    "\n",
    "#         self._distance_cache = None\n",
    "\n",
    "\n",
    "#     def fit(self, data : np.ndarray, k : int, debug : int = 0):\n",
    "#         \"\"\"\n",
    "#         Fit the model to the data.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         data : np.ndarray\n",
    "#             nxd DataFrame of n samples with d features\n",
    "#         k : int\n",
    "#             Number of clusters\n",
    "#         debug : int\n",
    "#             Debug level (0: no debug, 1: some debug, 2: all debug)\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         np.ndarray\n",
    "#             Array of shape (k, d) with cluster centroids\n",
    "#         np.ndarray\n",
    "#             Array of length n with cluster assignments for each sample\n",
    "#         \"\"\"\n",
    "\n",
    "#         assert isinstance(data, np.ndarray), \"data must be a numpy array\"\n",
    "#         assert len(data.shape) == 2, \"data must be a 2D array\"\n",
    "#         assert isinstance(k, int), \"k must be an int\"\n",
    "#         assert 0 < k <= len(data), \"k must be at least 0 and at most the number of samples\"\n",
    "#         assert isinstance(debug, int) or debug, \"debug must be an int\"\n",
    "\n",
    "#         self.data = data\n",
    "#         self.k = k\n",
    "#         self.n_samples = data.shape[0]\n",
    "#         self.l = np.zeros((self.n_samples, self.k))\n",
    "#         self.u = np.zeros((self.n_samples))\n",
    "\n",
    "#         np.random.seed(self.seed)\n",
    "\n",
    "#         # initialize centroids\n",
    "#         self._init_centroids(debug)\n",
    "#         debug and print('initial centroids:\\n', self.centroids)\n",
    "#         debug and print('initial y_pred:', self.y_pred)\n",
    "\n",
    "#         if self.algorithm == 'elkan':\n",
    "#             self._elkan(debug = debug)\n",
    "#         elif self.algorithm == 'acc-hartigan':\n",
    "#             self._acc_hartigan(debug = debug)\n",
    "        \n",
    "#         debug and print('final centroids:\\n', self.centroids)\n",
    "#         debug and print('final y_pred:', self.y_pred)\n",
    "\n",
    "\n",
    "#     def _init_centroids(self, debug=0):\n",
    "#         \"\"\"\n",
    "#         Initialize the centroids.\n",
    "#         \"\"\"\n",
    "\n",
    "#         v = 1\n",
    "\n",
    "#         if self.init == 'random':\n",
    "\n",
    "#             if v == 1:\n",
    "#                 # choose k random data points as initial centroids\n",
    "#                 idx = np.random.choice(self.n_samples, self.k, replace=False)\n",
    "#                 self.centroids = self.data[idx]\n",
    "#                 self.y_pred = self._assign_clusters(debug=debug>1)\n",
    "\n",
    "#             elif v == 2:\n",
    "#                 # choose k random data points as initial centroids\n",
    "#                 idx = np.random.choice(self.n_samples, self.k, replace=False)\n",
    "#                 self.centroids = self.data[idx]\n",
    "\n",
    "#                 self._distance_cache = cdist(self.data, self.centroids, metric='sqeuclidean')\n",
    "#                 self.y_pred = self._assign_clusters(debug=debug>1)\n",
    "\n",
    "#         elif self.init == 'random-data':\n",
    "#             return NotImplemented\n",
    "            \n",
    "#             # V1\n",
    "#             # assign each data point to a random cluster\n",
    "#             clusters = np.random.choice(self.k, self.n_samples)\n",
    "\n",
    "#             # check that at least one point is assigned to each cluster\n",
    "#             while len(set(clusters)) < self.k:\n",
    "#                 clusters = np.random.choice(self.k, self.n_samples)\n",
    "#             self.y_pred = clusters\n",
    "#             self.centroids = self._move_centroids(None, debug > 1)\n",
    "\n",
    "            \n",
    "#             # V2\n",
    "#             n_samples, n_features = self.data.shape\n",
    "#             # Assign each data point to a random cluster\n",
    "#             self.y_pred = np.random.choice(self.k, n_samples)\n",
    "#             # Ensure at least one point is assigned to each cluster\n",
    "#             unique_clusters = np.unique(self.y_pred)\n",
    "#             if len(unique_clusters) < self.k:\n",
    "#                 for i in range(self.k):\n",
    "#                     if i not in unique_clusters:\n",
    "#                         self.y_pred[np.random.randint(0, n_samples)] = i\n",
    "            \n",
    "#             self.centroids = np.zeros((self.k, n_features))\n",
    "#             # Calculate centroids efficiently\n",
    "#             for i in range(self.k):\n",
    "#                 mask = self.y_pred == i\n",
    "#                 if np.any(mask):\n",
    "#                     self.centroids[i] = np.mean(self.data[mask], axis=0)\n",
    "#                 else:\n",
    "#                     # Handle empty cluster\n",
    "#                     self.centroids[i] = self.data[np.random.randint(0, n_samples)]\n",
    "\n",
    "#         elif self.init == 'k-means++':\n",
    "            \n",
    "#             if v == 1:\n",
    "#                 # choose first centroid randomly\n",
    "#                 centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 centroids[0] = self.data[np.random.choice(self.n_samples, 1, replace=False)[0]]\n",
    "#                 debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid\n",
    "#                     dist = np.min(np.linalg.norm(self.data[:, np.newaxis] - centroids[:i], axis=2) ** 2, axis=1)\n",
    "\n",
    "#                     # probabilities are given by the normalized distance squared\n",
    "#                     probs = dist / dist.sum()\n",
    "#                     debug and print('probs:', probs)\n",
    "\n",
    "#                     # choose next centroid randomly based on cumulated probabilities\n",
    "#                     j = np.random.choice(self.n_samples, p=probs)\n",
    "\n",
    "#                     centroids[i] = self.data[j]\n",
    "#                     debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 self.centroids = centroids\n",
    "#                 self.y_pred = self._assign_clusters(debug=debug>1)\n",
    "\n",
    "#             elif v == 2:\n",
    "#                 # choose first centroid randomly\n",
    "#                 self.centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 first_idx = np.random.choice(self.n_samples)\n",
    "#                 self.centroids[0] = self.data[first_idx].copy()\n",
    "\n",
    "#                 debug and print('centroids:\\n', self.centroids)\n",
    "\n",
    "#                 # initialize min_distances with infinity\n",
    "#                 min_distances = np.full(self.n_samples, np.inf)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid (only calculate for new centroids)\n",
    "#                     new_distances = np.sum((self.data - self.centroids[i-1])**2, axis=1)\n",
    "#                     np.minimum(min_distances, new_distances, out=min_distances)\n",
    "\n",
    "#                     # probabilities are given by the normalized distance squared\n",
    "#                     probs = min_distances / np.sum(min_distances)\n",
    "#                     debug and print('probs:', probs)\n",
    "\n",
    "#                     # choose next centroid randomly based on cumulated probabilities\n",
    "#                     j = np.random.choice(self.n_samples, p=probs)\n",
    "\n",
    "#                     self.centroids[i] = self.data[j].copy()\n",
    "#                     debug and print('centroids:\\n', self.centroids)\n",
    "\n",
    "#                 self._distance_cache = cdist(self.data, self.centroids, metric='sqeuclidean')\n",
    "#                 self.y_pred = np.argmin(self._distance_cache, axis=1)\n",
    "\n",
    "#         elif self.init == 'maximin':\n",
    "\n",
    "#             if v == 1:\n",
    "#                 # choose first centroid randomly\n",
    "#                 centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 centroids[0] = self.data[np.random.choice(self.n_samples, 1, replace=False)[0]]\n",
    "#                 debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid\n",
    "#                     dist = np.min(np.linalg.norm(self.data[:, np.newaxis] - centroids[:i], axis=2) ** 2, axis=1)\n",
    "\n",
    "#                     # choose next centroid as the point with the maximum distance to the closest centroid\n",
    "#                     centroids[i] = self.data[np.argmax(dist)]\n",
    "#                     debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 self.centroids = centroids\n",
    "#                 self.y_pred = self._assign_clusters(debug=debug>1)\n",
    "\n",
    "#             elif v == 2:\n",
    "#                 # choose first centroid randomly\n",
    "#                 self.centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 first_idx = np.random.choice(self.n_samples)\n",
    "#                 self.centroids[0] = self.data[first_idx].copy()\n",
    "\n",
    "#                 # initialize min_distances with infinity\n",
    "#                 min_distances = np.full(self.n_samples, np.inf)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid (only calculate for new centroids)\n",
    "#                     new_distances = np.sum((self.data - self.centroids[i-1])**2, axis=1)\n",
    "#                     np.minimum(min_distances, new_distances, out=min_distances) \n",
    "\n",
    "#                     # choose next centroid as the point with the maximum min_distance to the closest centroid\n",
    "#                     self.centroids[i] = self.data[np.argmax(min_distances)].copy()\n",
    "#                     debug and print('centroids:\\n', self.centroids)\n",
    "\n",
    "#                 self._distance_cache = cdist(self.data, self.centroids, metric='sqeuclidean')\n",
    "#                 self.y_pred = np.argmin(self._distance_cache, axis=1)\n",
    "\n",
    "#         elif self.init == 'greedy-k-means++':\n",
    "\n",
    "#             if v == 1:\n",
    "#                 # TODO: this might be adapted\n",
    "#                 trials = 2 + int(np.log(self.k)) \n",
    "\n",
    "#                 # choose first centroid randomly\n",
    "#                 centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 f = np.random.choice(self.n_samples)\n",
    "#                 centroids[0] = self.data[f]\n",
    "#                 debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid\n",
    "#                     dist = np.min(np.linalg.norm(self.data[:, np.newaxis] - centroids[:i], axis=2) ** 2, axis=1)\n",
    "\n",
    "#                     # probabilities are given by the normalized distance squared\n",
    "#                     probs = dist / dist.sum()\n",
    "#                     debug and print('probs:', probs)\n",
    "\n",
    "#                     # choose next centroid randomly based on cumulated probabilities\n",
    "#                     candidate_j = np.random.choice(self.n_samples, size=trials, p=probs)\n",
    "#                     debug and print('candidate_j:', candidate_j)\n",
    "\n",
    "#                     # calculate the cost of each trial\n",
    "#                     costs = np.zeros(trials)\n",
    "#                     for t in range(trials):\n",
    "#                         centroids[i] = self.data[candidate_j[t]]\n",
    "#                         costs[t] = self._tot_cluster_cost(centroids, self._assign_clusters(specific_centroids=centroids), debug=debug>1)\n",
    "#                     debug and print('costs:', costs)\n",
    "\n",
    "#                     # choose the trial with the lowest cost\n",
    "#                     j = candidate_j[np.argmin(costs)]\n",
    "\n",
    "#                     centroids[i] = self.data[j]\n",
    "#                     debug and print('centroids:\\n', centroids)\n",
    "\n",
    "#                 self.centroids = centroids\n",
    "#                 self.y_pred = self._assign_clusters(debug=debug>1)\n",
    "\n",
    "#             elif v == 2:\n",
    "#                 # V2\n",
    "#                 # TODO: this might be adapted\n",
    "#                 trials = 2 + int(np.log(self.k)) \n",
    "\n",
    "#                 # choose first centroid randomly\n",
    "#                 self.centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#                 first_idx = np.random.choice(self.n_samples)\n",
    "#                 self.centroids[0] = self.data[first_idx].copy()\n",
    "\n",
    "#                 # initialize min_distances with infinity\n",
    "#                 min_distances = np.full(self.n_samples, np.inf)\n",
    "\n",
    "#                 # iterate over remaining k-1 centroids\n",
    "#                 for i in range(1, self.k):\n",
    "#                     debug and print('iteration', i)\n",
    "\n",
    "#                     # calculate squared distance of each point to closest centroid (only calculate for new centroids)\n",
    "#                     new_distances = np.sum((self.data - self.centroids[i-1])**2, axis=1)\n",
    "#                     np.minimum(min_distances, new_distances, out=min_distances)\n",
    "\n",
    "#                     # probabilities are given by the normalized distance squared\n",
    "#                     probs = min_distances / np.sum(min_distances)\n",
    "#                     debug and print('probs:', probs)\n",
    "\n",
    "#                     # choose next centroid randomly based on cumulated probabilities\n",
    "#                     candidate_j = np.random.choice(self.n_samples, size=trials, p=probs)\n",
    "#                     debug and print('candidate_j:', candidate_j)\n",
    "\n",
    "#                     # calculate the cost of each trial\n",
    "#                     best_cost = np.inf\n",
    "#                     best_idx = -1\n",
    "\n",
    "#                     # costs = np.zeros(trials)\n",
    "#                     for t in range(trials):\n",
    "#                         temp_centroids = self.centroids[:i].copy()\n",
    "#                         temp_centroids = np.vstack([temp_centroids, self.data[t]])\n",
    "\n",
    "#                         distances = cdist(self.data, temp_centroids, metric='sqeuclidean')\n",
    "#                         assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "#                         # calculate cost\n",
    "#                         cost = 0\n",
    "#                         for j in range(i+1):\n",
    "#                             mask = assignments == j\n",
    "#                             if np.any(mask):\n",
    "#                                 cost += np.sum(distances[mask, j])\n",
    "\n",
    "#                         if cost < best_cost:\n",
    "#                             best_cost = cost\n",
    "#                             best_idx = t\n",
    "                    \n",
    "#                     self.centroids[i] = self.data[best_idx].copy()\n",
    "\n",
    "#                     debug and print('centroids:\\n', self.centroids)\n",
    "\n",
    "#                 self._distance_cache = cdist(self.data, self.centroids, metric='sqeuclidean')\n",
    "#                 self.y_pred = np.argmin(self._distance_cache, axis=1)\n",
    "\n",
    "    \n",
    "#     def dist(self, x, y):\n",
    "#         \"\"\"\n",
    "#         Compute the squared Euclidean distance between two points.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         x : np.ndarray\n",
    "#             First point\n",
    "#         y : np.ndarray\n",
    "#             Second point\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         float\n",
    "#             Squared Euclidean distance between x and y\n",
    "#         \"\"\"\n",
    "#         self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "#         return np.sum((x - y)**2)\n",
    "\n",
    "#     # chat version\n",
    "#     def _elkan(self, debug=0):\n",
    "#         \"\"\"\n",
    "#         Elkan's algorithm for k-means clustering.\n",
    "#         \"\"\"\n",
    "#         debug and print(\"\\nRunning Elkan's algorithm...\")\n",
    "\n",
    "#         n, k = self.data.shape[0], self.k\n",
    "#         # Initialize bounds and distances\n",
    "#         upper_bounds = np.full((n,), np.inf)           # u[i]\n",
    "#         lower_bounds = np.zeros((n, k))                # l[i][j]\n",
    "#         center_dists = np.zeros((k, k))                # d[c][j]\n",
    "#         half_center_dists = np.zeros((k, k))           # s[c][j]\n",
    "\n",
    "#         old_y_pred = np.full(n, -1, dtype=int)\n",
    "\n",
    "#         # Precompute initial assignments\n",
    "#         self.y_pred = self._assign_clusters()\n",
    "        \n",
    "#         for i in range(n):\n",
    "#             upper_bounds[i] = np.linalg.norm(self.data[i] - self.centroids[self.y_pred[i]])\n",
    "#             self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "\n",
    "#         while True:\n",
    "#             debug and print(\"New iteration\")\n",
    "#             self.iterations += 1\n",
    "#             np.copyto(old_y_pred, self.y_pred)\n",
    "#             old_centroids = self.centroids.copy()\n",
    "\n",
    "#             # Step 1: compute distances between all pairs of centroids\n",
    "#             for c in range(k):\n",
    "#                 for j in range(k):\n",
    "#                     if c != j:\n",
    "#                         dist = np.linalg.norm(self.centroids[c] - self.centroids[j])\n",
    "#                         self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "#                         center_dists[c][j] = dist\n",
    "#                         half_center_dists[c][j] = dist / 2.0\n",
    "\n",
    "#             # Step 2: move centroids\n",
    "#             self.centroids = self._move_centroids(None, debug > 1)\n",
    "\n",
    "#             # Step 3: compute centroid movement distances\n",
    "#             centroid_shifts = np.linalg.norm(self.centroids - old_centroids, axis=1)\n",
    "#             self.norm_calculations += self.k / (self.k*self.n_samples)\n",
    "\n",
    "#             # Step 4: update upper and lower bounds\n",
    "#             for i in range(n):\n",
    "#                 upper_bounds[i] += centroid_shifts[self.y_pred[i]]\n",
    "#                 for j in range(k):\n",
    "#                     lower_bounds[i][j] = max(lower_bounds[i][j] - centroid_shifts[j], 0)\n",
    "\n",
    "#             # Step 5: reassign points\n",
    "#             for i in range(n):\n",
    "#                 c = self.y_pred[i]\n",
    "#                 skip = False\n",
    "#                 for j in range(k):\n",
    "#                     if j == c:\n",
    "#                         continue\n",
    "#                     if upper_bounds[i] <= lower_bounds[i][j]:\n",
    "#                         continue\n",
    "#                     if upper_bounds[i] <= half_center_dists[c][j]:\n",
    "#                         continue\n",
    "\n",
    "#                     # Otherwise, need to compute actual distance\n",
    "#                     if upper_bounds[i] == np.inf:\n",
    "#                         dist_to_c = np.linalg.norm(self.data[i] - self.centroids[c])\n",
    "#                         self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "#                     else:\n",
    "#                         dist_to_c = upper_bounds[i]\n",
    "#                     dist_to_j = np.linalg.norm(self.data[i] - self.centroids[j])\n",
    "#                     self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "\n",
    "#                     lower_bounds[i][j] = dist_to_j\n",
    "\n",
    "#                     if dist_to_j < dist_to_c:\n",
    "#                         c = j\n",
    "#                         dist_to_c = dist_to_j\n",
    "#                         upper_bounds[i] = dist_to_c\n",
    "\n",
    "#                 self.y_pred[i] = c\n",
    "\n",
    "#             if np.array_equal(old_y_pred, self.y_pred):\n",
    "#                 break\n",
    "\n",
    "\n",
    "#     # # v2\n",
    "#     # def _elkan(self, debug=0):\n",
    "#     #     \"\"\"\n",
    "#     #     Elkan's algorithm for k-means clustering, optimized with triangle inequality bounds.\n",
    "#     #     \"\"\"\n",
    "\n",
    "#     #     # Initialization\n",
    "#     #     r = np.full(self.n_samples, True)                      # All upper bounds need to be recomputed\n",
    "#     #     s = np.zeros(self.k)                                   # s[c] = half the distance to closest other centroid\n",
    "#     #     d = np.full((self.k, self.k), np.inf)                  # centroid distance matrix\n",
    "#     #     m = np.zeros_like(self.centroids)                      # new centroids (mean)\n",
    "\n",
    "#     #     # Set initial bounds\n",
    "#     #     for x in range(self.n_samples):\n",
    "#     #         for c in range(self.k):\n",
    "#     #             self.l[x, c] = self.dist(self.data[x], self.centroids[c])\n",
    "#     #         self.u[x] = self.l[x, self.y_pred[x]]\n",
    "\n",
    "#     #     while True:\n",
    "#     #         self.iterations += 1\n",
    "#     #         old_centroids = self.centroids.copy()\n",
    "#     #         old_pred = self.y_pred.copy()\n",
    "\n",
    "#     #         debug and print('\\nNew iteration')\n",
    "\n",
    "#     #         # 1. Compute centroid distances and s[c]\n",
    "#     #         for c in range(self.k):\n",
    "#     #             for cprime in range(c + 1, self.k):\n",
    "#     #                 dval = self.dist(self.centroids[c], self.centroids[cprime])\n",
    "#     #                 d[c, cprime] = d[cprime, c] = dval\n",
    "#     #             s[c] = 0.5 * np.min([d[c, j] for j in range(self.k) if j != c])\n",
    "\n",
    "#     #         # 2-3. Reassign points\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             assigned = self.y_pred[x]\n",
    "\n",
    "#     #             if self.u[x] <= s[assigned]:\n",
    "#     #                 continue\n",
    "\n",
    "#     #             if r[x]:\n",
    "#     #                 current_distance = self.dist(self.data[x], self.centroids[assigned])\n",
    "#     #                 self.u[x] = current_distance\n",
    "#     #                 r[x] = False\n",
    "#     #             else:\n",
    "#     #                 current_distance = self.u[x]\n",
    "\n",
    "#     #             for c in range(self.k):\n",
    "#     #                 if c == assigned:\n",
    "#     #                     continue\n",
    "\n",
    "#     #                 if self.u[x] <= self.l[x, c] or self.u[x] <= 0.5 * d[assigned, c]:\n",
    "#     #                     continue  # Triangle inequality allows skipping\n",
    "\n",
    "#     #                 # Compute distance and update lower bound\n",
    "#     #                 candidate_distance = self.dist(self.data[x], self.centroids[c])\n",
    "#     #                 self.l[x, c] = candidate_distance\n",
    "\n",
    "#     #                 if candidate_distance < current_distance:\n",
    "#     #                     self.y_pred[x] = c\n",
    "#     #                     current_distance = candidate_distance\n",
    "#     #                     self.u[x] = candidate_distance\n",
    "\n",
    "#     #         # 4. Compute new centroids\n",
    "#     #         for c in range(self.k):\n",
    "#     #             mask = self.y_pred == c\n",
    "#     #             if np.any(mask):\n",
    "#     #                 m[c] = np.mean(self.data[mask], axis=0)\n",
    "\n",
    "#     #         # 5. Update lower bounds\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             for c in range(self.k):\n",
    "#     #                 shift = self.dist(old_centroids[c], m[c])\n",
    "#     #                 self.l[x, c] = max(self.l[x, c] - shift, 0)\n",
    "\n",
    "#     #         # 6. Update upper bounds and mark r[x]\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             assigned = self.y_pred[x]\n",
    "#     #             self.u[x] += self.dist(old_centroids[assigned], m[assigned])\n",
    "#     #             r[x] = True\n",
    "\n",
    "#     #         # 7. Update centroids\n",
    "#     #         for c in range(self.k):\n",
    "#     #             if np.any(self.y_pred == c):\n",
    "#     #                 self.centroids[c] = m[c]\n",
    "\n",
    "#     #         # Check for convergence\n",
    "#     #         if np.all(old_pred == self.y_pred):\n",
    "#     #             break\n",
    "\n",
    "\n",
    "\n",
    "#     # v1\n",
    "#     # def _elkan(self, debug=0):\n",
    "\n",
    "#     #     r = np.full(self.n_samples, False)\n",
    "#     #     s = np.zeros(self.k)\n",
    "#     #     d = np.full((self.k, self.k), np.inf)\n",
    "#     #     m = np.zeros((self.k, self.data.shape[1]))\n",
    "\n",
    "        \n",
    "#     #     old_pred = np.zeros(self.n_samples, dtype=int)\n",
    "#     #     np.copyto(old_pred, self.y_pred)\n",
    "#     #     old_centroids = np.zeros((self.k, self.data.shape[1]))\n",
    "#     #     np.copyto(old_centroids, self.centroids)\n",
    "#     #     dist_change = np.zeros(self.k)\n",
    "\n",
    "#     #     self.centroids = self._move_centroids()\n",
    "\n",
    "#     #     for c in range(self.k):\n",
    "#     #         dist_change = self.dist(self.centroids[c], old_centroids[c])            \n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             self.l[x, c] -= dist_change\n",
    "#     #             self.u[x] += dist_change\n",
    "\n",
    "#     #     while True:\n",
    "#     #         self.iterations += 1\n",
    "#     #         old_centroids = self.centroids.copy()\n",
    "#     #         old_pred = self.y_pred.copy()\n",
    "\n",
    "#     #         debug and print('\\nNew iteration')\n",
    "            \n",
    "\n",
    "#     #         # 1. distance matrix of centers\n",
    "#     #         for c in range(self.k):\n",
    "#     #             for cprime in range(c, self.k):\n",
    "#     #                 d[c, cprime] = d[cprime, c] = self.dist(self.centroids[c], self.centroids[cprime])\n",
    "\n",
    "#     #             # s is the min over c' different from c\n",
    "#     #             s[c] = 0.5 * np.min(d[c, [i for i in range(self.k) if i != c]])\n",
    "\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             # 2. identify all points such that u(x) <= s(c(x))\n",
    "#     #             if self.u[x] <= s[self.y_pred[x]]:\n",
    "#     #                 continue\n",
    "\n",
    "#     #             else:\n",
    "#     #                 for c in range(self.k):\n",
    "#     #                     # 3.\n",
    "#     #                     if c != self.y_pred[x] and self.u[x] > self.l[x, c] and self.u[x] > 0.5 * d[self.y_pred[x], c]:\n",
    "\n",
    "#     #                         # 3a.\n",
    "#     #                         if r[x]:\n",
    "#     #                             self._distance_cache[x, self.y_pred[x]] = self.dist(self.data[x], self.centroids[self.y_pred[x]])\n",
    "#     #                             r[x] = False\n",
    "#     #                         else:\n",
    "#     #                             self._distance_cache[x, self.y_pred[x]] = self.u[x]\n",
    "\n",
    "#     #                         # 3b.\n",
    "#     #                         if self._distance_cache[x, self.y_pred[x]] > self.l[x, c] or self._distance_cache[x, self.y_pred[x]] > 0.5 * d[self.y_pred[x], c]:\n",
    "#     #                             if self.dist(self.data[x], self.centroids[c]) < self._distance_cache[x, self.y_pred[x]]:\n",
    "#     #                                 self.y_pred[x] = c\n",
    "                        \n",
    "#     #         # 4. for each center, caclulate the mean of points assigned to it\n",
    "#     #         for c in range(self.k):\n",
    "#     #             mask = self.y_pred == c\n",
    "#     #             points_in_cluster = self.data[mask]\n",
    "\n",
    "#     #             if np.any(mask):\n",
    "#     #                 # Vectorized computation\n",
    "#     #                 m[c] = np.mean(points_in_cluster, axis=0)\n",
    "\n",
    "#     #         # 5.\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             for c in range(self.k):\n",
    "#     #                 self.l[x, c] = max(self.l[x, c] - self.dist(old_centroids[c], m[c]), 0)\n",
    "#     #             self.u[x] += self.dist(old_centroids[self.y_pred[x]], m[self.y_pred[x]])\n",
    "#     #             r[x] = True\n",
    "\n",
    "#     #         # 6.\n",
    "#     #         for x in range(self.n_samples):\n",
    "#     #             self.u[x] += self.dist(m[self.y_pred[x]], self.centroids[self.y_pred[x]])\n",
    "#     #             r[x] = True\n",
    "\n",
    "#     #         # 7. replace each center c by m[c]\n",
    "#     #         for c in range(self.k):\n",
    "#     #             if np.any(self.y_pred == c):\n",
    "#     #                 self.centroids[c] = m[c]\n",
    "\n",
    "#     #         # check for convergence\n",
    "#     #         if np.all(old_pred == self.y_pred):\n",
    "#     #             break\n",
    "\n",
    "    \n",
    "#     def _acc_hartigan(self, debug=0):\n",
    "#         self.centroids = self._move_centroids(None, debug > 1)\n",
    "#         cluster_sizes = np.bincount(self.y_pred, minlength=self.k)\n",
    "\n",
    "#         # Initialize bounds\n",
    "#         u = np.zeros(self.n_samples)  # upper bounds\n",
    "#         l = np.zeros((self.n_samples, self.k))  # lower bounds\n",
    "#         d_cc = np.full((self.k, self.k), np.inf)  # centroid- centroid distances\n",
    "\n",
    "#         for i in range(self.n_samples):\n",
    "#             u[i] = self.dist(self.data[i], self.centroids[self.y_pred[i]])\n",
    "#             for c in range(self.k):\n",
    "#                 if c != self.y_pred[i]:\n",
    "#                     l[i, c] = max(0, self.dist(self.data[i], self.centroids[c]))\n",
    "\n",
    "#         edit = True\n",
    "#         while edit:\n",
    "#             self.iterations += 1\n",
    "#             edit = False\n",
    "\n",
    "#             # Update centroid-centroid distances and s[c]\n",
    "#             s = np.full(self.k, np.inf)\n",
    "#             for i in range(self.k):\n",
    "#                 for j in range(i + 1, self.k):\n",
    "#                     d_cc[i, j] = d_cc[j, i] = self.dist(self.centroids[i], self.centroids[j])\n",
    "#             for c in range(self.k):\n",
    "#                 s[c] = 0.5 * np.min([d_cc[c, j] for j in range(self.k) if j != c])\n",
    "\n",
    "#             for i in range(self.n_samples):\n",
    "#                 curr = self.y_pred[i]\n",
    "\n",
    "#                 if u[i] <= s[curr]:\n",
    "#                     continue  # Skip this point; it cannot move to any better cluster\n",
    "\n",
    "#                 best_cost_reduction = 0\n",
    "#                 best_target = None\n",
    "\n",
    "#                 for c in range(self.k):\n",
    "#                     if c == curr:\n",
    "#                         continue\n",
    "#                     if u[i] <= l[i, c]:\n",
    "#                         continue  # Prune using lower bound\n",
    "\n",
    "#                     # Hartigan cost difference\n",
    "#                     cost_out = -cluster_sizes[curr] / (cluster_sizes[curr] - 1) * self.dist(self.data[i], self.centroids[curr])\n",
    "#                     cost_in = cluster_sizes[c] / (cluster_sizes[c] + 1) * self.dist(self.data[i], self.centroids[c])\n",
    "#                     delta_cost = cost_out + cost_in\n",
    "\n",
    "#                     if delta_cost < best_cost_reduction:\n",
    "#                         best_cost_reduction = delta_cost\n",
    "#                         best_target = c\n",
    "\n",
    "#                 if best_target is not None:\n",
    "#                     old = curr\n",
    "#                     new = best_target\n",
    "\n",
    "#                     self.y_pred[i] = new\n",
    "#                     cluster_sizes[old] -= 1\n",
    "#                     cluster_sizes[new] += 1\n",
    "\n",
    "#                     # Update centroids\n",
    "#                     self.centroids[old] = np.mean(self.data[self.y_pred == old], axis=0)\n",
    "#                     self.centroids[new] = np.mean(self.data[self.y_pred == new], axis=0)\n",
    "\n",
    "#                     # Update bounds for i\n",
    "#                     u[i] = self.dist(self.data[i], self.centroids[new])\n",
    "#                     for c in range(self.k):\n",
    "#                         if c != new:\n",
    "#                             l[i, c] = max(l[i, c], self.dist(self.data[i], self.centroids[c]))\n",
    "\n",
    "#                     edit = True\n",
    "\n",
    "\n",
    "#     def _move_centroids(self, move_just = None, debug=0):\n",
    "#         \"\"\"\n",
    "#         Move the centroids to the mean of their cluster.\n",
    "#         \"\"\"\n",
    "\n",
    "#         debug and print('\\n  moving centroids...')\n",
    "#         debug and print('  | y_pred:', self.y_pred)\n",
    "#         debug and print('  | data:\\n', self.data)\n",
    "#         debug and print('  | centroids_before:\\n', self.centroids)\n",
    "\n",
    "#         centroids = np.copy(self.centroids)\n",
    "        \n",
    "#         move = move_just if move_just is not None else range(self.k)\n",
    "#         debug and print('  | move:', move)\n",
    "        \n",
    "#         for centroid_id in move:\n",
    "            \n",
    "#             mask = self.y_pred == centroid_id\n",
    "            \n",
    "#             # if centroid has no points assigned to it, reassign it randomly\n",
    "#             if np.any(mask):\n",
    "#                 centroids[centroid_id] = np.mean(self.data[mask], axis=0)\n",
    "#             else:\n",
    "#                 debug and print(f\"  Centroid {centroid_id} is empty. Reassigning.\")\n",
    "#                 new_centroid_id = np.random.choice(self.n_samples)\n",
    "#                 centroids[centroid_id] = self.data[new_centroid_id]\n",
    "#                 self.y_pred[new_centroid_id] = centroid_id\n",
    "\n",
    "#         debug and print('  centroids_after:\\n', centroids)\n",
    "\n",
    "#         return centroids\n",
    "\n",
    "\n",
    "#     def _assign_clusters(self, specific_centroids=None, debug=0):\n",
    "#         \"\"\"\n",
    "#         Assign each data point to the closest centroid.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         specific_centroids : np.ndarray\n",
    "#             array of shape (k', d) with specific centroids (of a specific number k') to use for the assignment\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         np.ndarray\n",
    "#             Array of length n with cluster assignments for each sample\n",
    "#         \"\"\"\n",
    "\n",
    "#         if specific_centroids is None:\n",
    "#             specific_centroids = self.centroids\n",
    "        \n",
    "#         self._distance_cache = cdist(self.data, specific_centroids, metric='sqeuclidean')\n",
    "#         y_pred = np.argmin(self._distance_cache, axis=1)\n",
    "#         self.norm_calculations += specific_centroids.shape[0] / (self.k*self.n_samples)\n",
    "\n",
    "#         # update upper and lower bounds\n",
    "#         # set l(x,c) = d(x,c)\n",
    "#         for i in range(self.n_samples):\n",
    "#             for j in range(self.k):\n",
    "#                 self.l[i,j] = self._distance_cache[i,j]\n",
    "\n",
    "#         self.u = np.zeros(self.n_samples)\n",
    "#         for i in range(self.n_samples):\n",
    "#             self.u[i] = np.min(self._distance_cache[i])\n",
    "        \n",
    "#         debug and print('y_pred:', y_pred)\n",
    "\n",
    "#         return y_pred\n",
    "\n",
    "\n",
    "#     def _tot_cluster_cost(self, centroids, points_ids, debug=0):\n",
    "#         \"\"\"\n",
    "#         Compute the overall cost of clustering\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         centroids : np.ndarray\n",
    "#             Array of shape ('k, d) with cluster centroids\n",
    "#         points_ids : np.ndarray\n",
    "#             Array of length n with cluster assignments for each sample\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         float\n",
    "#             Total cost of clustering\n",
    "#         \"\"\"\n",
    "        \n",
    "#         debug and print('\\n  calculating _tot_cluster_cost')\n",
    "        \n",
    "#         total_cost = 0\n",
    "\n",
    "#         for centroid_id in range(centroids.shape[0]):\n",
    "#             mask = points_ids == centroid_id\n",
    "#             points_in_cluster = self.data[mask]\n",
    "\n",
    "#             cluster_items = np.where(points_ids == centroid_id)[0]\n",
    "\n",
    "#             if len(points_in_cluster) > 0:\n",
    "#                 # Vectorized computation\n",
    "#                 cost = np.sum(np.sum((points_in_cluster - centroids[centroid_id])**2, axis=1))\n",
    "#                 total_cost += cost\n",
    "#                 self.norm_calculations += len(cluster_items) / (self.k*self.n_samples)\n",
    "\n",
    "#             debug and print('  | centroid_id:', centroid_id)\n",
    "#             debug and print('  | centroid:', centroids[centroid_id])\n",
    "#             debug and print('  | cluster_items:', cluster_items)\n",
    "#             debug and print('  | cost:', cost)\n",
    "        \n",
    "#         debug and print(f'  total_cost: {total_cost}')\n",
    "        \n",
    "#         return total_cost\n",
    "\n",
    "\n",
    "#     def _find_candidates(self, datapoint_id, candidates, debug=0):\n",
    "#         \"\"\"\n",
    "#         Find candidates for reassignment of a single datapoint.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # calculate sizes of clusters and cost of current assignment\n",
    "#         cluster_sizes = np.bincount(self.y_pred, minlength=self.k)\n",
    "\n",
    "#         current_centroid_id = self.y_pred[datapoint_id]\n",
    "#         current_size = cluster_sizes[current_centroid_id]\n",
    "        \n",
    "#         # if current clsuter has only one point, we cannot move it\n",
    "#         if current_size <= 1:\n",
    "#             return candidates\n",
    "        \n",
    "#         prefactor = current_size / (current_size - 1)\n",
    "#         current_cost = prefactor * np.sum((self.data[datapoint_id] - self.centroids[current_centroid_id])**2)\n",
    "#         self.norm_calculations += 1/(self.k*self.n_samples)\n",
    "\n",
    "#         debug and print('current_cost:', current_cost)\n",
    "\n",
    "#         # if current_cost is 0, delta_cost will always be positive\n",
    "#         if current_cost == 0:\n",
    "#             return candidates\n",
    "        \n",
    "#         # Vectorized computation for all centroids except the current one\n",
    "#         mask = np.arange(self.k) != current_centroid_id\n",
    "#         cluster_sizes_masked = cluster_sizes[mask]\n",
    "#         valid_centroid_ids = np.where(mask)[0]\n",
    "\n",
    "#         # Compute delta costs\n",
    "#         delta_costs = (cluster_sizes_masked / (cluster_sizes_masked + 1)) * np.linalg.norm(self.data[datapoint_id] - self.centroids[valid_centroid_ids], axis=1)**2 - current_cost\n",
    "#         self.norm_calculations += (len(cluster_sizes_masked)) / (self.k*self.n_samples)\n",
    "\n",
    "#         # Find the best centroid (most negative delta_cost)\n",
    "#         best_idx = np.argmin(delta_costs)\n",
    "#         best_delta_cost = delta_costs[best_idx]\n",
    "\n",
    "#         if best_delta_cost < 0:\n",
    "#             best_centroid_id = valid_centroid_ids[best_idx]\n",
    "#             candidates[datapoint_id] = [best_delta_cost, current_centroid_id, best_centroid_id]\n",
    "        \n",
    "#         return candidates\n",
    "\n",
    "\n",
    "#     def _accept_candidates(self, candidates, debug=0):\n",
    "#         \"\"\"\n",
    "#         Accepts all candidates passed as argument and calculates new total cluster cost.\n",
    "#         \"\"\"\n",
    "#         # accept all candidates\n",
    "#         used_centroids = set()\n",
    "\n",
    "#         for datapoint_id, [_, current_centroid_id, new_centroid_id] in candidates.items():\n",
    "\n",
    "#             debug and print('candidate:', datapoint_id)\n",
    "\n",
    "#             used_centroids.add(current_centroid_id)\n",
    "#             used_centroids.add(new_centroid_id)\n",
    "\n",
    "#             debug and print('y_pred before:', self.y_pred)\n",
    "\n",
    "#             # update closest_points_ids assigning datapoint to new_centroid_id\n",
    "#             self.y_pred[datapoint_id] = new_centroid_id\n",
    "#             debug and print('y_pred after:', self.y_pred)\n",
    "\n",
    "#         new_centroids = self._move_centroids(move_just=used_centroids, debug = debug)\n",
    "\n",
    "#         return self._tot_cluster_cost(new_centroids, self.y_pred, debug), new_centroids"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
